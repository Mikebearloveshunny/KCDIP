{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8876034",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28535,
     "status": "ok",
     "timestamp": 1688480509811,
     "user": {
      "displayName": "Cheng-Che Tsai",
      "userId": "06148275036649066160"
     },
     "user_tz": -480
    },
    "id": "c8876034",
    "outputId": "8b8d3e3d-61da-4de1-cf61-3d38b3f244fb"
   },
   "outputs": [],
   "source": [
    "DEV_MODE = False\n",
    "\n",
    "if DEV_MODE:\n",
    "    class TestArg():\n",
    "        def __init__(self, factor):\n",
    "            self.file = \"/work/users/c/c/cctsai/data/BCP_sample/357_T1w_MPR_NORM_3.npy\"\n",
    "            self.factor = factor\n",
    "            self.model_folder = \"dev_mode\"\n",
    "            self.input_img = False\n",
    "            \n",
    "    args = TestArg(factor=2)\n",
    "else:\n",
    "    from argparse import ArgumentParser\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--file\")\n",
    "    parser.add_argument(\"--factor\")\n",
    "    \n",
    "    #basic config\n",
    "    parser.add_argument(\"--model_folder\")\n",
    "    parser.add_argument(\"--input_img\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--double_arm\", default=\"False\")\n",
    "        \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "_name_ = args.file.split(\"/\")[-1].split(\".\")[0]\n",
    "model_folder = args.model_folder\n",
    "\n",
    "factor = float(args.factor)  #1.25, 1.5, 1.75, 2    \n",
    "    \n",
    "import os, sys, glob\n",
    "sys.path.append(\"./utils\")\n",
    "res_dir = f\"/work/users/c/c/cctsai/res/{model_folder}/{_name_}/{int(factor*100)}\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "from utils_unet3D_ver3 import *\n",
    "from utils_kspace_torch import *\n",
    "from utils.models import *\n",
    "from utils.prep import *\n",
    "from utils.sr_common import *\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "for new_dir in [res_dir, f\"{res_dir}/model\", f\"{res_dir}/log\"]:\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "\n",
    "import datetime\n",
    "current_time = datetime.datetime.now().time()\n",
    "print_log = lambda msg: write_log(msg, f'{res_dir}/log/age{_name_}_factor{factor*100}_{current_time}.txt') # from prep.py\n",
    "\n",
    "print_log(f\"Task name: {_name_}, factor={factor}\")\n",
    "\n",
    "# save the argument in the output txt\n",
    "arguments_dict = vars(args)\n",
    "arguments_string = \"\\n\".join([f\"{key}: {value}\" for key, value in arguments_dict.items()])\n",
    "print_log(arguments_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5857f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality = 'T1'\n",
    "\n",
    "input_depth = 1\n",
    "INPUT =     'noise'\n",
    "OPT_OVER =  'net'\n",
    "\n",
    "LR = 0.0001\n",
    "lambda_reg = 0.00001\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "num_iter = 8200\n",
    "reg_noise_std = 0\n",
    "\n",
    "downsampler = lambda img: torch_sinc_downsampler_3D(img, factor)\n",
    "downsampler2 = lambda img: torch_sinc_downsampler_3D(img, factor*factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7fxFf7q7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2029,
     "status": "ok",
     "timestamp": 1688480511837,
     "user": {
      "displayName": "Cheng-Che Tsai",
      "userId": "06148275036649066160"
     },
     "user_tz": -480
    },
    "id": "2eb7fxFf7q7f",
    "outputId": "d054e563-fce8-48d5-e24b-c53168dbc3f5"
   },
   "outputs": [],
   "source": [
    "img_HR_np = np.load(args.file)\n",
    "if DEV_MODE:\n",
    "    img_HR_np = img_HR_np[:160, :160, :160]\n",
    "\n",
    "img_HR_np = nor(img_HR_np)\n",
    "img_LR_tensor = downsampler(img_HR_np)\n",
    "img_LR_tensor = torch.clamp(img_LR_tensor, min=0.0, max=1.0)\n",
    "\n",
    "img_LR2_tensor = downsampler2(img_HR_np)\n",
    "img_LR2_tensor = torch.clamp(img_LR2_tensor, min=0.0, max=1.0)\n",
    "\n",
    "imgs = {'orig_np':img_HR_np,\n",
    "        'LR_np': img_LR_tensor.numpy()\n",
    "       }\n",
    "\n",
    "# image kspace\n",
    "img_LR_var =  torch.clone(img_LR_tensor).type(dtype)\n",
    "net_input = torch.clone(img_LR2_tensor).unsqueeze(0).unsqueeze(0).type(dtype)\n",
    "\n",
    "print_log(f'input shape: {net_input.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67bee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = asym_UNet3D(in_channels=input_depth, out_channels=1, trilinear=True, factor=factor).cuda()\n",
    "MSE = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf4a6dc",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1688480513040,
     "user": {
      "displayName": "Cheng-Che Tsai",
      "userId": "06148275036649066160"
     },
     "user_tz": -480
    },
    "id": "6bf4a6dc"
   },
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global i, net_input\n",
    "    net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "    \n",
    "    gen_LR = net(net_input)\n",
    "    main_loss1 = MSE(gen_LR[0,0], img_LR_var)\n",
    "    \n",
    "    total_loss = main_loss1\n",
    "\n",
    "    l2_reg = 0\n",
    "    for param in net.parameters():\n",
    "        l2_reg += torch.norm(param)\n",
    "    total_loss = total_loss+lambda_reg*l2_reg\n",
    "    total_loss.backward()\n",
    "\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        # kspace_replacement\n",
    "        out_HR = net(gen_LR)\n",
    "        \n",
    "        dip_img = torch2np(out_HR[0][0])\n",
    "        dip_img_central_replacement = central_replacement_3d(imgs['orig_np'], dip_img, factor=factor)\n",
    "\n",
    "        # psnr\n",
    "        psnr_SS = volumetric_psnr(imgs['LR_np'], gen_LR[0,0]) #SS: self-supervised\n",
    "        psnr_HR = volumetric_psnr(imgs['orig_np'], dip_img)\n",
    "        psnr_kr = volumetric_psnr(imgs['orig_np'], dip_img_central_replacement)\n",
    "        ssim_index = compare_ssim(imgs['orig_np'], dip_img, channel_axis=None)\n",
    "        ssim_index_kr = compare_ssim(imgs['orig_np'], dip_img_central_replacement, channel_axis=None)\n",
    "\n",
    "       #1001 newly add \n",
    "        item_list = [(\"Iteration %05d\", i), (\"PSNR_SS %.3f\", psnr_SS), (\"PSNR_HR %.3f\", psnr_HR),\n",
    "             (\"PSNR_KR %.3f\", psnr_kr), (\"SSIM %.3f\", ssim_index), (\"SSIM_KR %.3f\", ssim_index_kr),\n",
    "             (\"Loss %.5f\", total_loss), (\"img_mse %.5f\", main_loss1), \n",
    "             (\"reg_term %.5f\", lambda_reg*l2_reg)]\n",
    "\n",
    "        output_line = save_info_dict(item_list, info_path=f'{res_dir}/log/info_dict_factor{factor*100}')\n",
    "        print_log(output_line)\n",
    "        \n",
    "#         print_log('Iteration %05d  PSNR_LR %.3f  PSNR_HR %.3f  PSNR_KR %.3f | SSIM %.3f  SSIM_KR %.3f | Loss %.5f  Img_mse %.5f  kspace_mse %.5f  kspace_boundary %.5f' % \n",
    "#                   (i, psnr_LR, psnr_HR, psnr_kr, ssim_index, ssim_index_kr, total_loss, main_loss1, kspace_mse1, kspace_boundary_loss))\n",
    " \n",
    "        if i>2000:\n",
    "            out_HR_np = torch_to_np(out_HR)\n",
    "            np.save(f'{res_dir}/HR_volume_{i}.npy', out_HR_np[0])\n",
    "        if i%1000 ==0:\n",
    "            torch.save(net.state_dict(), f'{res_dir}/model/epoch{i}_model_weights.pth')\n",
    "    i += 1\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa16f3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7990505,
     "status": "error",
     "timestamp": 1688488503541,
     "user": {
      "displayName": "Cheng-Che Tsai",
      "userId": "06148275036649066160"
     },
     "user_tz": -480
    },
    "id": "3aa16f3e",
    "outputId": "2a9ee497-beb0-439b-f5d7-3a5dc2940f18",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#epo_cont_ =\n",
    "#model_weights = torch.load(f'{res_dir}/epo{epo_cont_}model_weights.pth')\n",
    "#net.load_state_dict(model_weights)\n",
    "\n",
    "net_input_saved = net_input.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "\n",
    "i = 0\n",
    "p = get_params(OPT_OVER, net, net_input)\n",
    "optimize(OPTIMIZER, p, closure, LR, num_iter)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "13iyaFx8etnFRHZv0bCjk3aN3mXVPPn0J",
     "timestamp": 1688480445459
    },
    {
     "file_id": "105N2Ws1HRPedH29X3sa3f-n8CuGfYQ43",
     "timestamp": 1688479969222
    },
    {
     "file_id": "1uHKG_Q7ENjhcp8sUtHs5nQeZbWWF0D1n",
     "timestamp": 1688283748542
    },
    {
     "file_id": "1ObIlU5aM4yCoKBfq9_rKaSWWgsnJJo9O",
     "timestamp": 1688283274320
    },
    {
     "file_id": "1ET8tEnykIssaG1CyEOJQnzj234dIQos_",
     "timestamp": 1688218636580
    },
    {
     "file_id": "1I52Hk_EAtdi6hhifSJa5n9Oyuw3uIXlg",
     "timestamp": 1688212408983
    },
    {
     "file_id": "1d0zDomofIuN_mKHs1ndxeXkRF2sxigeq",
     "timestamp": 1688211917695
    },
    {
     "file_id": "1WsG-N2VdgPflRMBWMYUleXrZT6FfIW3u",
     "timestamp": 1687765562594
    },
    {
     "file_id": "1ihehHAAB5tDEHUWjhwWeVFifTAh1me2S",
     "timestamp": 1687765015540
    },
    {
     "file_id": "1v4Tx2Rvqfjt4-JIjJ1Gf2niTfqcwO-Af",
     "timestamp": 1686984620725
    },
    {
     "file_id": "168e2Pkv7uhL2vXfrRbqKmiHK2-16RBCB",
     "timestamp": 1686666612660
    },
    {
     "file_id": "1j57YXXgZY1EXtQuoZlqvapdpM2z0MhSu",
     "timestamp": 1686665691741
    },
    {
     "file_id": "18lTtU4yX6-23P0ag7vse04pBkLkWaabl",
     "timestamp": 1686388188197
    },
    {
     "file_id": "19xP80tLbspBV0oFIzMN-5cM3VV4yRxIz",
     "timestamp": 1686061449809
    },
    {
     "file_id": "1sT_Jrvv1vxCHvPcFgmJucR12_yD7OFHd",
     "timestamp": 1686059199201
    },
    {
     "file_id": "1rT9xpjivF-L81Tu6syn0G7wUJ6ULzVTW",
     "timestamp": 1686059027283
    },
    {
     "file_id": "1TiGnlauw_VOBEHilT8Z8xi3Y37nm2Qhh",
     "timestamp": 1685186560060
    },
    {
     "file_id": "1Rmc-b35IufBOH4oPSR3xOvDiREbmh__B",
     "timestamp": 1684852886729
    },
    {
     "file_id": "1-orxQ23qZgYfToP3j9nHnwrwp9U7OHBi",
     "timestamp": 1684844183585
    },
    {
     "file_id": "1dJ8a8tRnFg-RBn9KbtlWgNZbvh5iC8Ts",
     "timestamp": 1684587551960
    },
    {
     "file_id": "1QQObuL6tL3qIqwIOsph0UoKqhQlKNtxw",
     "timestamp": 1684587026619
    },
    {
     "file_id": "1Ar6vTBC3sU8EBd4LLAeuN0OjdjgYzA0l",
     "timestamp": 1684258663461
    },
    {
     "file_id": "1NIORZmPCMR17kzs-3xvKGnIfgna9f7ue",
     "timestamp": 1684257172927
    },
    {
     "file_id": "1KnGKYG5kvDbt_dhBfgpR_ltciHPeiBd3",
     "timestamp": 1684255896415
    },
    {
     "file_id": "1FEImuoJDFRuYt68b6WWaCd6xtuVrIuzS",
     "timestamp": 1683647081896
    },
    {
     "file_id": "1YpAsBWhr8khZFpOsOUclHkpOL7tfBPed",
     "timestamp": 1682389442709
    },
    {
     "file_id": "1x3XYSzMki93XfuPsqTX0LwtLQLQYSViR",
     "timestamp": 1682368199937
    },
    {
     "file_id": "1BgZvX4mQuDRTZ74tHjEzUqW6boA8slK8",
     "timestamp": 1682364346059
    },
    {
     "file_id": "1YFrhpTicjW_kw8aXam8pY2yGXcgN33Da",
     "timestamp": 1680622463520
    },
    {
     "file_id": "1xPSrJcqJeqZ2HTEFt9hbe8Y8zuDEa2Jq",
     "timestamp": 1680011001642
    },
    {
     "file_id": "1NRmvLhfpyPxxkd2b0m2Tsb4wHWQQGNg4",
     "timestamp": 1678913339931
    },
    {
     "file_id": "1nAmUpUcTlECdQB22-IPxszZIImQXQnWe",
     "timestamp": 1678912432807
    },
    {
     "file_id": "163h9233D9R-1uHZKZv2ALYOeUpWL4Gzr",
     "timestamp": 1678893406962
    },
    {
     "file_id": "1tuUe0AkGuLTd2x_n3aolXi2j6lozBGKP",
     "timestamp": 1678674535665
    }
   ]
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
