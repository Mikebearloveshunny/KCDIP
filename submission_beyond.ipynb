{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f49abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task name: 357_T1w_MPR_NORM_3, factor=2.0\n",
      "file: /work/users/c/c/cctsai/data/BCP_sample/357_T1w_MPR_NORM_3.npy\n",
      "factor: 2\n",
      "model_folder: dev_mode\n",
      "input_img: True\n",
      "double_arm: True\n",
      "kspace_mse: True\n",
      "kspace_boundary: True\n",
      "kbound_weight: 0.0005\n",
      "kbound_lower: 0.95\n",
      "kspace_mse_shape: u\n",
      "kspace_mse_weight: 1.0\n",
      "kbound_outer_layer: True\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--file\")\n",
    "parser.add_argument(\"--factor\")\n",
    "parser.add_argument(\"--model_folder\") #-> if not specified, create a folder for it\n",
    "parser.add_argument(\"--method\", default='kcdip') # -> can be chosen\n",
    "\n",
    "# can be customized\n",
    "parser.add_argument(\"--kspace_mse_shape\", default='v') # -> can be chosen\n",
    "parser.add_argument(\"--kspace_boundary\", action=\"store_true\", default=False) #can be chosen\n",
    "parser.add_argument(\"--double_arm\", default=\"True\") # -> can be chosen\n",
    "parser.add_argument(\"--kspace_mse\", action=\"store_true\", default=False) #-> fixed\n",
    "\n",
    "args = parser.parse_args()\n",
    "    \n",
    "\n",
    "######  set up ######\n",
    "configs = dict()\n",
    "\n",
    "configs['file'] = args.file\n",
    "configs['model_folder'] = args.model_folder\n",
    "configs['factor'] = float(args.factor)  #1.25, 1.5, 1.75, 2    \n",
    "configs['method'] = args.method\n",
    "\n",
    "import json\n",
    "with open(\"default_settings.json\", \"r\") as json_file:\n",
    "    default_settings = json.load(json_file)\n",
    "\n",
    "if configs['method'] in ['kcdip','dip','diptv']:\n",
    "    configs.update(default_settings[configs['method']])\n",
    "\n",
    "import os, sys, glob\n",
    "sys.path.append(\"./utils\")\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "###\n",
    "from utils_unet3D_ver3 import *\n",
    "from utils_kspace_torch import *\n",
    "from utils.models import *\n",
    "from utils.prep import *\n",
    "from utils.sr_common import *\n",
    "\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%H%M%S\")\n",
    "res_dir = f\"{configs['model_folder']}/{current_time}\"\n",
    "\n",
    "# save the argument in the output txt\n",
    "print_log = lambda msg: write_log(msg, f'{res_dir}/log/{current_time}.txt')\n",
    "\n",
    "args_dict = vars(args)\n",
    "args_string = \"\\n\".join([f\"{key}: {value}\" for key, value in args_dict.items()])\n",
    "print_log(args_string)\n",
    "print_log(\"Start!\")\n",
    "\n",
    "\n",
    "for new_dir in [res_dir, f\"{res_dir}/model\", f\"{res_dir}/log\"]:\n",
    "    os.makedirs(new_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e82016",
   "metadata": {},
   "outputs": [],
   "source": [
    "TWOARM_RATIO = 1/5 # ratio between unsupervsied and self-supervised\n",
    "INPUT =     'noise'\n",
    "OPT_OVER =  'net'\n",
    "\n",
    "LR = 0.0001 #learning rate\n",
    "KSPACE_WEIGHT = 0.0001\n",
    "KBOUND_WEIGHT = 0.0001*5\n",
    "KBOUND_LOWER = 0.95\n",
    "LAMBDA_REG = 0.00001 # net weight regulation\n",
    "OPTIMIZER = 'adam'\n",
    "reg_noise_std = 0.03 # random noise regulation\n",
    "\n",
    "\n",
    "downsampler = lambda img: torch_sinc_downsampler_3D(img, factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85cd79d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 96, 96])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chop_cube(arr):\n",
    "    off=48\n",
    "    return arr[off:-off, off:-off, off:-off]\n",
    "\n",
    "img_HR_np = np.load(configs[\"file\"])\n",
    "img_HR_np = chop_cube(img_HR_np)\n",
    "img_HR_np = nor(img_HR_np)\n",
    "\n",
    "# image kspace\n",
    "img_HR_var =  torch.from_numpy(img_HR_np).type(dtype)\n",
    "img_HR_kspace = to_k_space(img_HR_var)\n",
    "\n",
    "# inputs\n",
    "HR_size = img_HR_np.shape[-1]\n",
    "SR_size = int(img_HR_np.shape[-1]*factor)\n",
    "\n",
    "net_input = get_noise_3d(input_depth, INPUT, (SR_size,SR_size,SR_size)).type(dtype).detach()\n",
    "net_input2 = downsampler(net_input[0][0]).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "print_log(f'input1 shape: {net_input.shape}')\n",
    "print_log(f'input2 shape: {net_input2.shape}')\n",
    "\n",
    "#net\n",
    "filter_n = 64\n",
    "net = UNet3D(in_channels=1, out_channels=1, filter_n=filter_n, trilinear=True, conv_residual=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56bd299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ksapce_mask(shape, size):\n",
    "    if shape.lower()=='v':\n",
    "        kspace_mask = torch.zeros((size,size,size))\n",
    "        for half_size in range(1, size//2+1):\n",
    "            if half_size ==size:\n",
    "                value = half_size//2\n",
    "            else:\n",
    "                value = half_size\n",
    "            kspace_mask = fill_3D_shell(kspace_mask, half_size, value)\n",
    "\n",
    "        kspace_mask = kspace_mask/kspace_mask.max()\n",
    "    \n",
    "    elif shape.lower()=='u':\n",
    "        kspace_mask = torch.zeros((size,size,size))\n",
    "        mag = np.linspace(0,5,size//2)\n",
    "        kweight = np.power(2, mag)  \n",
    "        for half_size in range(1, size//2+1):\n",
    "            if half_size ==size:\n",
    "                value = kweight[half_size-1]/2\n",
    "            else:\n",
    "                value = kweight[half_size-1]\n",
    "            kspace_mask = fill_3D_shell(kspace_mask, half_size, value)\n",
    "\n",
    "        kspace_mask = kspace_mask/kspace_mask.max()\n",
    "        \n",
    "    elif shape.lower()=='i':\n",
    "        kspace_mask = torch.ones((size,size,size))\n",
    "    return kspace_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d72e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if configs[\"kspace_mse\"] or configs[\"kspace_boundary\"]:\n",
    "    assert configs[\"kspace_mse_shape\"].lower() in ['u','v','i']\n",
    "    \n",
    "    kspace_mask = gen_ksapce_mask(configs[\"kspace_mse_shape\"], LR_size).type(dtype)\n",
    "    kspace_mask2 = central_crop_3D(kspace_mask, factor)\n",
    "    kspace_mask2 = kspace_mask2.type(dtype)\n",
    "\n",
    "    def kspace_loss(z_pred, z_true, kspace_mask=kspace_mask):\n",
    "        z_diff = z_pred - z_true\n",
    "\n",
    "        # Calculate the absolute value of the difference (real, imag) and square each element\n",
    "        z_abs_sq = torch.square(torch.abs(z_diff))\n",
    "        z_abs_sq = z_abs_sq*kspace_mask\n",
    "\n",
    "        # Calculate the mean squared error (MSE) loss in complex number space\n",
    "        mse_loss = torch.mean(z_abs_sq)\n",
    "        return mse_loss\n",
    "\n",
    "\n",
    "def charbonnier_loss(prediction, target, epsilon=1e-6):\n",
    "    error = torch.sqrt((prediction - target)**2 + epsilon**2)\n",
    "    loss = torch.mean(error)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def kboundary_loss_fn(LR_kspace, HR_kspace, factor, kbound_lower):\n",
    "    bd_idx = LR_kspace.shape[-1]\n",
    "    \n",
    "    HR_kspace = HR_kspace/(factor**3)\n",
    "    HR_kspace_abs = torch.abs(HR_kspace)\n",
    "    LR_kspace_abs = torch.abs(LR_kspace)\n",
    "\n",
    "    HR_shell_mean = get_3D_shell(HR_kspace_abs, bd_idx).mean()\n",
    "    LR_shell_mean = get_3D_shell(LR_kspace_abs, bd_idx-1).mean()\n",
    "\n",
    "    # CHANGED TO MSE, FROM L1 LOSS\n",
    "    diff = torch.pow(HR_shell_mean - LR_shell_mean, 2)\n",
    "    first_loss = diff if((HR_shell_mean > 0.99*LR_shell_mean) or (HR_shell_mean < kbound_lower*LR_shell_mean)) else 0\n",
    "    loss = first_loss\n",
    "\n",
    "    return loss, first_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3c270d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    global i, net_input, net_input2\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "        net_input2 = net_input2_saved + (noise2.normal_() * reg_noise_std)\n",
    "\n",
    "    out_SR = net(net_input)\n",
    "    out_SR_kspace = to_k_space(out_SR[0][0])\n",
    "    out_HR_kspace = central_crop_3D(out_SR_kspace, factor)/(factor**3)\n",
    "    out_HR = inv_fft(out_HR_kspace)\n",
    "    out_HR = torch.clamp(out_HR, min=0.0, max=1.0)\n",
    "    \n",
    "    main_loss1 = charbonnier_loss(out_HR, img_HR_var)\n",
    "    total_loss = main_loss1\n",
    "\n",
    "    if configs[\"double_arm\"]==\"True\":\n",
    "        out_HR2 = net(net_input2)\n",
    "        out_HR2 = torch.clamp(out_HR2, min=0.0, max=1.0)\n",
    "        out_HR2_kspace = to_k_space(out_HR2[0][0])\n",
    "        main_loss2 = charbonnier_loss(out_HR2, img_HR_var)\n",
    "        total_loss = total_loss + (twoarm_ratio*main_loss2)\n",
    "\n",
    "    # Compute L2 regularization term for the last layer\n",
    "    l2_reg = 0\n",
    "    for param in net.parameters():\n",
    "        l2_reg += torch.norm(param)\n",
    "    total_loss = total_loss + LAMBDA_REG*l2_reg\n",
    "    \n",
    "    \"\"\"kspace loss\"\"\"\n",
    "    #kspace_mse\n",
    "    if configs[\"kspace_mse\"]:\n",
    "        kspace_mse1 = KSPACE_WEIGHT*kspace_loss(out_HR_kspace, img_HR_kspace)\n",
    "        total_loss = total_loss + kspace_mse1 \n",
    "        \n",
    "        if configs[\"double_arm\"]==\"True\":\n",
    "            kspace_mse2 = KSPACE_WEIGHT*kspace_loss(out_HR2_kspace, img_HR_kspace)\n",
    "            total_loss = total_loss + (twoarm_ratio*kspace_mse2)\n",
    "        \n",
    "    if configs[\"kspace_boundary\"]:\n",
    "        kboundary_total_loss, kboundary_first_loss = kboundary_loss_fn(img_HR_kspace, out_SR_kspace, factor, KBOUND_LOWER, KBOUND_OUTER_LAYER)\n",
    "        kspace_boundary_loss = KBOUND_WEIGHT*kboundary_total_loss\n",
    "        total_loss = total_loss + kspace_boundary_loss\n",
    "    total_loss.backward()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # psnr\n",
    "        psnr_hR = volumetric_psnr(img_HR_np, out_HR)\n",
    "        item_list = [(\"Iteration %05d\", i), (\"PSNR_hR %.3f\", psnr_hR), \n",
    "             (\"Loss %.5f\", total_loss), (\"img_mse %.5f\", main_loss1), \n",
    "             (\"reg_term %.5f\", LAMBDA_REG*l2_reg)]\n",
    "        \n",
    "        if configs[\"double_arm\"]==\"True\":            \n",
    "            psnr_hR2 = volumetric_psnr(img_HR_np, out_HR2[0][0]) #  HR2 is actually at the dimension of LR\n",
    "            item_list += [(\"sec_img_mse %.5f\", twoarm_ratio*main_loss2), (\"PSNR_hR2 %.3f\", psnr_hR2)]\n",
    "            \n",
    "        if configs[\"kspace_mse\"]:\n",
    "            item_list += [(\"kspace_mse %.5f\", kspace_mse1)]\n",
    "            if configs[\"double_arm\"]==\"True\":\n",
    "                item_list += [(\"sec_kspace_mse %.5f\", twoarm_ratio*kspace_mse2)]\n",
    "                \n",
    "        if configs[\"kspace_boundary\"]:\n",
    "            item_list += [(\"kspace_boundary %.5f\", kspace_boundary_loss)]\n",
    "\n",
    "        output_line = save_info_dict(item_list, info_path=f'{res_dir}/log/info_dict_factor{factor*100}')\n",
    "        print_log(output_line)\n",
    "\n",
    "        if i>2000:            \n",
    "            out_SR_np = torch_to_np(out_SR)\n",
    "            np.save(f'{res_dir}/SR_volume_{i}.npy', out_SR_np[0])\n",
    "        if i%1000 ==0:\n",
    "            torch.save(net.state_dict(), f'{res_dir}/model/epoch{i}_model_weights.pth')\n",
    "    i += 1\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization with ADAM\n",
      "Iteration 00000  PSNR_hR 11.633  Loss 8.71903  img_mse 0.25997  reg_term 0.00146  sec_img_mse 0.05155  PSNR_hR2 11.749  kspace_mse 0.27104  sec_kspace_mse 0.08181  kspace_boundary 8.05321  \n",
      "Iteration 00100  PSNR_hR 19.170  Loss 0.48350  img_mse 0.10582  reg_term 0.00146  sec_img_mse 0.02304  PSNR_hR2 16.752  kspace_mse 0.14008  sec_kspace_mse 0.03447  kspace_boundary 0.17863  \n"
     ]
    }
   ],
   "source": [
    "net_input_saved = net_input.detach().clone()\n",
    "net_input2_saved = net_input2.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "noise2 = net_input2.detach().clone()\n",
    "\n",
    "i = 0\n",
    "p = get_params(OPT_OVER, net, net_input)\n",
    "optimize(OPTIMIZER, p, closure, LR, num_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
