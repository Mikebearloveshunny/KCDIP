{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d06dec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_n = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f49abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task name: 357_T1w_MPR_NORM_3, factor=2.0\n",
      "file: /work/users/c/c/cctsai/data/BCP_sample/357_T1w_MPR_NORM_3.npy\n",
      "factor: 2\n",
      "model_folder: dev_mode\n",
      "input_img: True\n",
      "double_arm: True\n",
      "kspace_mse: True\n",
      "kspace_boundary: True\n",
      "kbound_weight: 0.0005\n",
      "kbound_lower: 0.95\n",
      "kspace_mse_shape: u\n",
      "kspace_mse_weight: 1.0\n",
      "kbound_outer_layer: True\n"
     ]
    }
   ],
   "source": [
    "DEV_MODE = False\n",
    "\n",
    "if DEV_MODE:\n",
    "    class TestArg():\n",
    "        def __init__(self, file, factor):\n",
    "            self.file = file\n",
    "            self.factor = factor\n",
    "            self.model_folder = \"dev_mode\"\n",
    "            self.input_img = True\n",
    "            self.double_arm = \"True\"\n",
    "            self.kspace_mse = True\n",
    "            self.kspace_boundary = True\n",
    "            self.kbound_weight = 0.0001*5\n",
    "            self.kbound_lower = 0.95\n",
    "            self.kspace_mse_shape = 'u'\n",
    "            self.kspace_mse_weight = 1.\n",
    "            self.kbound_outer_layer = 'True' \n",
    "            \n",
    "    args = TestArg(file=\"/work/users/c/c/cctsai/data/BCP_sample/357_T1w_MPR_NORM_3.npy\", factor=2)\n",
    "else:\n",
    "    from argparse import ArgumentParser\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument(\"--file\")\n",
    "    parser.add_argument(\"--factor\")\n",
    "    \n",
    "    #basic config\n",
    "    parser.add_argument(\"--model_folder\")\n",
    "    parser.add_argument(\"--input_img\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--double_arm\", default=\"True\")\n",
    "    \n",
    "    #loss config\n",
    "    parser.add_argument(\"--SSIM\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--kspace_mse\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--kspace_mse_shape\", default='v')\n",
    "    parser.add_argument(\"--kspace_mse_weight\", default=1.)\n",
    "    \n",
    "    #kspace boundary\n",
    "    parser.add_argument(\"--kspace_boundary\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--kbound_weight\", default = 0.0001*5)\n",
    "    parser.add_argument(\"--kbound_lower\", default = 0.95)\n",
    "    parser.add_argument(\"--kbound_outer_layer\", default = \"True\")\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "_name_ = args.file.split(\"/\")[-1].split(\".\")[0]\n",
    "model_folder = args.model_folder\n",
    "\n",
    "factor = float(args.factor)  #1.25, 1.5, 1.75, 2    \n",
    "kspace_mse_weight = float(args.kspace_mse_weight)\n",
    "    \n",
    "import os, sys, glob\n",
    "sys.path.append(\"./utils\")\n",
    "res_dir = f\"/work/users/c/c/cctsai/res/{model_folder}/{_name_}/{int(factor*100)}\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "from utils_unet3D_ver3 import *\n",
    "from utils_kspace_torch import *\n",
    "from utils.models import *\n",
    "from utils.prep import *\n",
    "from utils.sr_common import *\n",
    "\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64\"\n",
    "\n",
    "\n",
    "for new_dir in [res_dir, f\"{res_dir}/model\", f\"{res_dir}/log\"]:\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "\n",
    "import datetime\n",
    "current_time = datetime.datetime.now().time()\n",
    "print_log = lambda msg: write_log(msg, f'{res_dir}/log/age{_name_}_factor{factor*100}_{current_time}.txt') # from prep.py\n",
    "\n",
    "print_log(f\"Task name: {_name_}, factor={factor}\")\n",
    "\n",
    "# save the argument in the output txt\n",
    "arguments_dict = vars(args)\n",
    "arguments_string = \"\\n\".join([f\"{key}: {value}\" for key, value in arguments_dict.items()])\n",
    "print_log(arguments_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb653a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality = 'T1'\n",
    "twoarm_ratio = 1/5\n",
    "\n",
    "input_depth = 1\n",
    "INPUT =     'noise'\n",
    "OPT_OVER =  'net'\n",
    "\n",
    "LR = 0.0001\n",
    "kspace_weight = 0.0001 #stronger from 0.0001\n",
    "kspace_boundary_weight = float(args.kbound_weight)\n",
    "KBOUND_LOWER = float(args.kbound_lower)\n",
    "KBOUND_OUTER_LAYER = args.kbound_outer_layer\n",
    "\n",
    "\n",
    "lambda_reg = 0.00001\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "num_iter = 15000\n",
    "reg_noise_std = 0.03\n",
    "\n",
    "if args.input_img:\n",
    "    reg_noise_std = 0\n",
    "\n",
    "downsampler = lambda img: torch_sinc_downsampler_3D(img, factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85cd79d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 96, 96])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chop_cube(arr):\n",
    "    off=48\n",
    "    return arr[off:-off, off:-off, off:-off]\n",
    "\n",
    "img_HR_np = np.load(args.file)\n",
    "img_HR_np = chop_cube(img_HR_np)\n",
    "img_HR_np = nor(img_HR_np) \n",
    "\n",
    "# image kspace\n",
    "img_HR_var =  torch.from_numpy(img_HR_np).type(dtype)\n",
    "img_HR_kspace = to_k_space(img_HR_var)\n",
    "\n",
    "# shape\n",
    "img_HR_kspace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f70cef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1 shape: torch.Size([1, 1, 192, 192, 192])\n",
      "input2 shape: torch.Size([1, 1, 96, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "#net\n",
    "net = UNet3D(in_channels=input_depth, out_channels=1, filter_n=filter_n, trilinear=True, conv_residual=True).cuda()\n",
    "\n",
    "# inputs\n",
    "# side=img_HR_np.shape[-1]\n",
    "side = img_HR_np.shape[-1]*2\n",
    "\n",
    "# if not args.input_img:\n",
    "#     net_input = get_noise_3d(input_depth, INPUT, (side,side,side)).type(dtype).detach()\n",
    "# else:\n",
    "#     upsampled = sinc_upsampler(img_LR_tensor, side, factor)\n",
    "#     net_input = upsampled.unsqueeze(0).unsqueeze(0).type(dtype)\n",
    "net_input = get_noise_3d(input_depth, INPUT, (side,side,side)).type(dtype).detach()\n",
    "\n",
    "net_input2 = downsampler(net_input[0][0]).unsqueeze(0).unsqueeze(1)\n",
    "print_log(f'input1 shape: {net_input.shape}')\n",
    "print_log(f'input2 shape: {net_input2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56bd299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ksapce_mask(shape, size):\n",
    "    if shape.lower()=='v':\n",
    "        kspace_mask = torch.zeros((size,size,size))\n",
    "        for half_size in range(1, size//2+1):\n",
    "            if half_size ==size:\n",
    "                value = half_size//2\n",
    "            else:\n",
    "                value = half_size\n",
    "            kspace_mask = fill_3D_shell(kspace_mask, half_size, value)\n",
    "\n",
    "        kspace_mask = kspace_mask/kspace_mask.max()\n",
    "    \n",
    "    elif shape.lower()=='u':\n",
    "        kspace_mask = torch.zeros((size,size,size))\n",
    "        mag = np.linspace(0,5,size//2)\n",
    "        kweight = np.power(2, mag)  \n",
    "        for half_size in range(1, size//2+1):\n",
    "            if half_size ==size:\n",
    "                value = kweight[half_size-1]/2\n",
    "            else:\n",
    "                value = kweight[half_size-1]\n",
    "            kspace_mask = fill_3D_shell(kspace_mask, half_size, value)\n",
    "\n",
    "        kspace_mask = kspace_mask/kspace_mask.max()\n",
    "        \n",
    "    elif shape.lower()=='i':\n",
    "        kspace_mask = torch.ones((size,size,size))*kspace_mse_weight\n",
    "    return kspace_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d72e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(side//factor)\n",
    "\n",
    "if args.kspace_mse or args.kspace_boundary:\n",
    "    assert args.kspace_mse_shape.lower() in ['u','v','i']\n",
    "    \n",
    "    kspace_mask = gen_ksapce_mask(args.kspace_mse_shape, size).type(dtype)\n",
    "    kspace_mask2 = central_crop_3D(kspace_mask, factor)\n",
    "    #kspace_mask2 = kspace_mask2/kspace_mask2.max()\n",
    "    kspace_mask2 = kspace_mask2.type(dtype)\n",
    "\n",
    "    def kspace_loss(z_pred, z_true, kspace_mask=kspace_mask):\n",
    "        # = out_LR_kspace, img_LR_kspace\n",
    "        z_diff = z_pred - z_true\n",
    "\n",
    "        # Calculate the absolute value of the difference (real, imag) and square each element\n",
    "        z_abs_sq = torch.square(torch.abs(z_diff))\n",
    "        z_abs_sq = z_abs_sq*kspace_mask\n",
    "\n",
    "        # Calculate the mean squared error (MSE) loss in complex number space\n",
    "        mse_loss = torch.mean(z_abs_sq)\n",
    "        return mse_loss\n",
    "\n",
    "# def sum_abs(tensor):\n",
    "#     return torch.sum(torch.abs(tensor))\n",
    "\n",
    "\n",
    "def charbonnier_loss(prediction, target, epsilon=1e-6):\n",
    "    error = torch.sqrt((prediction - target)**2 + epsilon**2)\n",
    "    loss = torch.mean(error)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def kboundary_loss_fn(LR_kspace, HR_kspace, factor, kbound_lower, kbound_outer_layer):\n",
    "    bd_idx = 16 if DEV_MODE else 48\n",
    "    \n",
    "    HR_kspace = HR_kspace/(factor**3)\n",
    "    HR_kspace_abs = torch.abs(HR_kspace)\n",
    "    LR_kspace_abs = torch.abs(LR_kspace)\n",
    "\n",
    "    HR_shell_mean = get_3D_shell(HR_kspace_abs, bd_idx).mean()\n",
    "    LR_shell_mean = get_3D_shell(LR_kspace_abs, bd_idx-1).mean()\n",
    "\n",
    "    # CHANGED TO MSE, FROM L1 LOSS\n",
    "    diff = torch.pow(HR_shell_mean - LR_shell_mean, 2)\n",
    "    first_loss = diff if((HR_shell_mean > 0.99*LR_shell_mean) or (HR_shell_mean < kbound_lower*LR_shell_mean)) else 0\n",
    "    loss = first_loss\n",
    "\n",
    "    if kbound_outer_layer=='True':\n",
    "        #loss_weight_decay_rate = 0.95\n",
    "        for layer in range(bd_idx+1, bd_idx+2):\n",
    "            previous_shell_mean = get_3D_shell(HR_kspace_abs, layer-1).mean()\n",
    "            current_shell_mean = get_3D_shell(HR_kspace_abs, layer).mean()\n",
    "            diff = torch.pow(previous_shell_mean - current_shell_mean, 2)\n",
    "            loss += diff if ((current_shell_mean > 0.99*previous_shell_mean) or (current_shell_mean < kbound_lower*previous_shell_mean)) else 0\n",
    "\n",
    "    return loss, first_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3c270d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total loss\n",
    "#total_loss = main_loss1 + kspace_mse1 + twoarm_ratio*(main_loss2 + kspace_mse2) + kspace_boundary_loss + lambda_reg*l2_reg\n",
    "\n",
    "def closure():\n",
    "    global i, net_input, net_input2\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "        net_input2 = net_input2_saved + (noise2.normal_() * reg_noise_std)\n",
    "\n",
    "#     out_HR = net(net_input)\n",
    "#     out_HR_kspace = to_k_space(out_HR[0][0])\n",
    "#     out_LR_kspace = central_crop_3D(out_HR_kspace, factor)/(factor**3)\n",
    "#     out_LR = inv_fft(out_LR_kspace)\n",
    "#     out_LR = torch.clamp(out_LR, min=0.0, max=1.0)\n",
    "    out_SR = net(net_input)\n",
    "    out_SR_kspace = to_k_space(out_SR[0][0])\n",
    "    out_HR_kspace = central_crop_3D(out_SR_kspace, factor)/(factor**3)\n",
    "    out_HR = inv_fft(out_HR_kspace)\n",
    "    out_HR = torch.clamp(out_HR, min=0.0, max=1.0)\n",
    "    \n",
    "#     main_loss1 = charbonnier_loss(out_LR, img_LR_var)\n",
    "    main_loss1 = charbonnier_loss(out_HR, img_HR_var)\n",
    "    total_loss = main_loss1\n",
    "\n",
    "    if args.double_arm==\"True\":\n",
    "        out_HR2 = net(net_input2)\n",
    "        out_HR2 = torch.clamp(out_HR2, min=0.0, max=1.0)\n",
    "        out_HR2_kspace = to_k_space(out_HR2[0][0])\n",
    "        main_loss2 = charbonnier_loss(out_HR2, img_HR_var)\n",
    "        total_loss = total_loss + (twoarm_ratio*main_loss2)\n",
    "\n",
    "    # Compute L2 regularization term for the last layer\n",
    "    l2_reg = 0\n",
    "    for param in net.parameters():\n",
    "        l2_reg += torch.norm(param)\n",
    "    total_loss = total_loss+lambda_reg*l2_reg\n",
    "    \n",
    "    \"\"\"kspace loss\"\"\"\n",
    "    #kspace_mse\n",
    "    if args.kspace_mse:\n",
    "#         kspace_mse1 = kspace_weight*kspace_loss(out_LR_kspace, img_LR_kspace)\n",
    "        kspace_mse1 = kspace_weight*kspace_loss(out_HR_kspace, img_HR_kspace)\n",
    "        total_loss = total_loss + kspace_mse1 \n",
    "        \n",
    "        if args.double_arm==\"True\":\n",
    "#             kspace_mse2 = kspace_weight*kspace_loss(out_HR2_kspace, img_LR_kspace)\n",
    "            kspace_mse2 = kspace_weight*kspace_loss(out_HR2_kspace, img_HR_kspace)\n",
    "            total_loss = total_loss + (twoarm_ratio*kspace_mse2)\n",
    "        \n",
    "    if args.kspace_boundary:\n",
    "#         kboundary_total_loss, kboundary_first_loss = kboundary_loss_fn(img_LR_kspace, out_HR_kspace, factor, KBOUND_LOWER, KBOUND_OUTER_LAYER)\n",
    "        kboundary_total_loss, kboundary_first_loss = kboundary_loss_fn(img_HR_kspace, out_SR_kspace, factor, KBOUND_LOWER, KBOUND_OUTER_LAYER)\n",
    "        kspace_boundary_loss = kspace_boundary_weight*kboundary_total_loss\n",
    "        total_loss = total_loss + kspace_boundary_loss\n",
    "    total_loss.backward()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # kspace_replacement\n",
    "#         dip_img = out_HR[0][0].detach().cpu().numpy()\n",
    "#         dip_img_central_replacement = central_replacement_3d(imgs['orig_np'], dip_img, factor=factor)\n",
    "\n",
    "        # psnr\n",
    "        psnr_hR = volumetric_psnr(img_HR_np, out_HR)\n",
    "#         psnr_LR = volumetric_psnr(imgs['LR_np'], out_HR)\n",
    "#         psnr_HR = volumetric_psnr(imgs['orig_np'], dip_img)\n",
    "#         psnr_kr = volumetric_psnr(imgs['orig_np'], dip_img_central_replacement)\n",
    "#         ssim_index = compare_ssim(imgs['orig_np'], dip_img, data_range=1.0, channel_axis=None)\n",
    "#         ssim_index_kr = compare_ssim(imgs['orig_np'], dip_img_central_replacement, data_range=1.0, channel_axis=None)\n",
    "\n",
    "       #1001 newly add \n",
    "#         item_list = [(\"Iteration %05d\", i), (\"PSNR_LR %.3f\", psnr_LR), (\"PSNR_HR %.3f\", psnr_HR),\n",
    "#              (\"PSNR_KR %.3f\", psnr_kr), (\"SSIM %.3f\", ssim_index), (\"SSIM_KR %.3f\", ssim_index_kr),\n",
    "#              (\"Loss %.5f\", total_loss), (\"img_mse %.5f\", main_loss1), \n",
    "#              (\"reg_term %.5f\", lambda_reg*l2_reg)]\n",
    "        item_list = [(\"Iteration %05d\", i), (\"PSNR_hR %.3f\", psnr_hR), \n",
    "             (\"Loss %.5f\", total_loss), (\"img_mse %.5f\", main_loss1), \n",
    "             (\"reg_term %.5f\", lambda_reg*l2_reg)]\n",
    "        \n",
    "        if args.double_arm==\"True\":\n",
    "#             psnr_LR2 = volumetric_psnr(imgs['LR_np'], out_HR2[0][0]) #  HR2 is actually at the dimension of LR\n",
    "#             item_list += [(\"sec_img_mse %.5f\", twoarm_ratio*main_loss2), (\"PSNR_LR2 %.3f\", psnr_LR2)]\n",
    "            \n",
    "            psnr_hR2 = volumetric_psnr(img_HR_np, out_HR2[0][0]) #  HR2 is actually at the dimension of LR\n",
    "            item_list += [(\"sec_img_mse %.5f\", twoarm_ratio*main_loss2), (\"PSNR_hR2 %.3f\", psnr_hR2)]\n",
    "            \n",
    "            \n",
    "        if args.kspace_mse:\n",
    "            item_list += [(\"kspace_mse %.5f\", kspace_mse1)]\n",
    "            if args.double_arm==\"True\":\n",
    "                item_list += [(\"sec_kspace_mse %.5f\", twoarm_ratio*kspace_mse2)]\n",
    "                \n",
    "        if args.kspace_boundary:\n",
    "            item_list += [(\"kspace_boundary %.5f\", kspace_boundary_loss)]\n",
    "\n",
    "        output_line = save_info_dict(item_list, info_path=f'{res_dir}/log/info_dict_factor{factor*100}')\n",
    "        print_log(output_line)\n",
    "        \n",
    "#         print_log('Iteration %05d  PSNR_LR %.3f  PSNR_HR %.3f  PSNR_KR %.3f | SSIM %.3f  SSIM_KR %.3f | Loss %.5f  Img_mse %.5f  kspace_mse %.5f  kspace_boundary %.5f' % \n",
    "#                   (i, psnr_LR, psnr_HR, psnr_kr, ssim_index, ssim_index_kr, total_loss, main_loss1, kspace_mse1, kspace_boundary_loss))\n",
    " \n",
    "        if i>2000:\n",
    "#             out_HR_np = torch_to_np(out_HR)\n",
    "#             np.save(f'{res_dir}/HR_volume_{i}.npy', out_HR_np[0])\n",
    "            \n",
    "            out_SR_np = torch_to_np(out_SR)\n",
    "            np.save(f'{res_dir}/SR_volume_{i}.npy', out_SR_np[0])\n",
    "        if i%1000 ==0:\n",
    "            torch.save(net.state_dict(), f'{res_dir}/model/epoch{i}_model_weights.pth')\n",
    "    i += 1\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6416102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization with ADAM\n",
      "Iteration 00000  PSNR_hR 11.633  Loss 8.71903  img_mse 0.25997  reg_term 0.00146  sec_img_mse 0.05155  PSNR_hR2 11.749  kspace_mse 0.27104  sec_kspace_mse 0.08181  kspace_boundary 8.05321  \n",
      "Iteration 00100  PSNR_hR 19.170  Loss 0.48350  img_mse 0.10582  reg_term 0.00146  sec_img_mse 0.02304  PSNR_hR2 16.752  kspace_mse 0.14008  sec_kspace_mse 0.03447  kspace_boundary 0.17863  \n"
     ]
    }
   ],
   "source": [
    "#epo_cont_ =\n",
    "#model_weights = torch.load(f'{res_dir}/epo{epo_cont_}model_weights.pth')\n",
    "#net.load_state_dict(model_weights)\n",
    "\n",
    "net_input_saved = net_input.detach().clone()\n",
    "net_input2_saved = net_input2.detach().clone()\n",
    "noise = net_input.detach().clone()\n",
    "noise2 = net_input2.detach().clone()\n",
    "\n",
    "i = 0\n",
    "p = get_params(OPT_OVER, net, net_input)\n",
    "optimize(OPTIMIZER, p, closure, LR, num_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
