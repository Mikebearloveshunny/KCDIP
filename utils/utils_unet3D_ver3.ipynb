{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2214710",
   "metadata": {
    "id": "d2214710"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# (v) batchNorm -> InstanceNorm #nn.BatchNorm3d(out_channels), #InstanceNorm\n",
    "# residual connection\n",
    "# ReLu -> LeakyReLu\n",
    "\n",
    "from prep import *\n",
    "from sr_common import *\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_residual=False, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.InstanceNorm3d(out_channels), # (v) batchNorm -> InstanceNorm\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm3d(out_channels), # (v) batchNorm -> InstanceNorm\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_residual=False):\n",
    "        super().__init__()\n",
    "        self.mpconv = nn.Sequential(\n",
    "            nn.MaxPool3d(2),     #use trilinear pooling\n",
    "            DoubleConv(in_channels, out_channels, conv_residual)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mpconv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, conv_residual=False, trilinear=False):\n",
    "        super().__init__()\n",
    "        if trilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose3d(in_channels//2, in_channels//2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels, conv_residual)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        #x1 is from the mainstreaml; x2 is from the skip connection\n",
    "        x1 = self.up(x1)\n",
    "        '''\n",
    "        diffZ = x2.size()[2] - x1.size()[2]\n",
    "        diffY = x2.size()[3] - x1.size()[3]\n",
    "        diffX = x2.size()[4] - x1.size()[4]\n",
    "        x1 = nn.functional.pad(x1, (diffX // 2, diffX - diffX // 2,\n",
    "                                    diffY // 2, diffY - diffY // 2,\n",
    "                                    diffZ // 2, diffZ - diffZ // 2))\n",
    "        '''\n",
    "        # Calculate padding dynamically based on the size difference between x2 and x1\n",
    "        padding_dims = [0, 0, 0, 0, 0, 0]  # Initialize padding dimensions\n",
    "        for dim in range(3):\n",
    "            size_diff = x2.size(dim+2) - x1.size(dim+2)\n",
    "            if size_diff % 2 == 0:\n",
    "                # If the size difference is even, split it evenly on both sides\n",
    "                padding_dims[2 * dim] = size_diff // 2\n",
    "                padding_dims[2 * dim + 1] = size_diff // 2\n",
    "            else:\n",
    "                # If the size difference is odd, add the extra pixel to the end\n",
    "                padding_dims[2 * dim] = size_diff // 2\n",
    "                padding_dims[2 * dim + 1] = size_diff // 2 + 1\n",
    "\n",
    "        # Apply padding to x1\n",
    "        x1 = nn.functional.pad(x1, tuple(padding_dims))\n",
    "        \n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, filter_n = 64, trilinear=False, conv_residual=False):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(in_channels, filter_n)\n",
    "        self.down1 = Down(filter_n, filter_n*2)\n",
    "        self.down2 = Down(filter_n*2, filter_n*4)\n",
    "        self.down3 = Down(filter_n*4, filter_n*8)\n",
    "        self.down4 = Down(filter_n*8, filter_n*8)\n",
    "        self.up1 = Up(filter_n*16, filter_n*4, trilinear=trilinear)\n",
    "        self.up2 = Up(filter_n*8, filter_n*2, trilinear=trilinear)\n",
    "        self.up3 = Up(filter_n*4, filter_n, trilinear=trilinear)\n",
    "        self.up4 = Up(filter_n*2, filter_n, trilinear=trilinear)\n",
    "        self.out = nn.Conv3d(filter_n, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        # (v) Add a few layers (merge the features previously learned)\n",
    "        out = self.out(x)\n",
    "        out = torch.sigmoid(out)  # apply sigmoid activation function\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4873a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class asym_UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, factor, trilinear=False, filter_n = 64):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(in_channels, filter_n)\n",
    "        self.down1 = Down(filter_n, filter_n*2)\n",
    "        self.down2 = Down(filter_n*2, filter_n*4)\n",
    "        self.down3 = Down(filter_n*4, filter_n*8)\n",
    "        self.down4 = Down(filter_n*8, filter_n*8)\n",
    "        self.up1 = Up(filter_n*16, filter_n*4, trilinear=trilinear)\n",
    "        self.up2 = Up(filter_n*8, filter_n*2, trilinear=trilinear)\n",
    "        self.up3 = Up(filter_n*4, filter_n, trilinear=trilinear)\n",
    "        self.up4 = Up(filter_n*2, filter_n, trilinear=trilinear)\n",
    "        \n",
    "        self.final_up = nn.Upsample(scale_factor=factor, mode='trilinear', align_corners=True)\n",
    "        self.out = nn.Conv3d(filter_n, out_channels, kernel_size=1)\n",
    "#         self.out = DoubleConv(filter_n, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        # (v) Add a few layers (merge the features previously learned)\n",
    "        x = self.final_up(x)\n",
    "        out = self.out(x)\n",
    "        out = torch.sigmoid(out)  # apply sigmoid activation function\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eXCFqdgwiI0R",
   "metadata": {
    "id": "eXCFqdgwiI0R"
   },
   "outputs": [],
   "source": [
    "def create_highpass_filter(kernel_size, normalize=False):\n",
    "    # Create a 3D high-pass filter\n",
    "    highpass_filter = torch.ones(1, 1, kernel_size, kernel_size, kernel_size)\n",
    "    center_pixel = kernel_size // 2\n",
    "    key_value = kernel_size ** 3 - 1\n",
    "    highpass_filter[0, 0, center_pixel, center_pixel, center_pixel] = -(key_value)\n",
    "    if normalize:\n",
    "        return highpass_filter/key_value\n",
    "    else:\n",
    "        return highpass_filter\n",
    "\n",
    "# # Example usage\n",
    "# kernel_size = 3\n",
    "# highpass_filter = create_highpass_filter(kernel_size)\n",
    "\n",
    "\n",
    "class SharpBlock(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size):\n",
    "        super(SharpBlock, self).__init__()\n",
    "        # kernel = torch.Tensor(\n",
    "        #     [[[-1, -1, -1], [-1,  -1, -1],[-1, -1, -1]],\n",
    "        #      [[-1, -1, -1], [-1,  8, -1],[-1, -1, -1]],\n",
    "        #       [[-1, -1, -1], [-1,  -1, -1],[-1, -1, -1]]])\n",
    "\n",
    "        kernel = create_highpass_filter(kernel_size)\n",
    "\n",
    "        #self.weight = nn.Parameter(data=kernel.unsqueeze(0).repeat(in_channels, 1, 1, 1), requires_grad=False)\n",
    "        #self.weight = nn.Parameter(data=kernel.unsqueeze(0).unsqueeze(1).repeat(in_channels, 1, 1, 1, 1), requires_grad=False)\n",
    "        self.weight = nn.Parameter(data=kernel.repeat(in_channels, 1, 1, 1, 1), requires_grad=False)\n",
    "        #self.depthwise_conv = nn.Conv3d(in_channels, in_channels, kernel_size=3, stride=1, padding=1, groups=in_channels, bias=False)\n",
    "        self.depthwise_conv = nn.Conv3d(in_channels, in_channels, kernel_size=kernel_size, stride=1, padding='same', groups=in_channels, bias=False)\n",
    "        self.depthwise_conv.weight = self.weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise_conv(x)\n",
    "        return x\n",
    "\n",
    "class SharpUNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, filter_n = 64, trilinear=False, conv_residual=False):\n",
    "        super().__init__()\n",
    "        self.inc = DoubleConv(in_channels, filter_n)\n",
    "        self.down1 = Down(filter_n, filter_n*2)\n",
    "        self.down2 = Down(filter_n*2, filter_n*4)\n",
    "        self.down3 = Down(filter_n*4, filter_n*8)\n",
    "        self.down4 = Down(filter_n*8, filter_n*8)\n",
    "\n",
    "        self.sb1 = SharpBlock(filter_n, 3) #in_channels, kernel_size\n",
    "        self.sb2 = SharpBlock(filter_n*2, 5)\n",
    "        self.sb3 = SharpBlock(filter_n*4, 7)\n",
    "        self.sb4 = SharpBlock(filter_n*8, 9)\n",
    "\n",
    "        self.up1 = Up(filter_n*16, filter_n*4, trilinear=trilinear)\n",
    "        self.up2 = Up(filter_n*8, filter_n*2, trilinear=trilinear)\n",
    "        self.up3 = Up(filter_n*4, filter_n, trilinear=trilinear)\n",
    "        self.up4 = Up(filter_n*2, filter_n, trilinear=trilinear)\n",
    "        self.out = nn.Conv3d(filter_n, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        x4 = self.sb4(x4)\n",
    "        x3 = self.sb3(x3)\n",
    "        x2 = self.sb2(x2)\n",
    "        x1 = self.sb1(x1)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        # (v) Add a few layers (merge the features previously learned)\n",
    "        out = self.out(x)\n",
    "        out = torch.sigmoid(out)  # apply sigmoid activation function\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "J0I9sjRnuz_4",
   "metadata": {
    "id": "J0I9sjRnuz_4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38e92468",
   "metadata": {
    "id": "38e92468"
   },
   "outputs": [],
   "source": [
    "def get_noise_3d(input_depth, method, noise_size, noise_type='u', var=1./10):\n",
    "    \"\"\"Returns a pytorch.Tensor of size (1 x `input_depth` x `spatial_size[0]` x `spatial_size[1]`)\n",
    "    initialized in a specific way.\n",
    "    Args:\n",
    "        input_depth: number of channels in the tensor\n",
    "        method: `noise` for fillting tensor with noise; `meshgrid` for np.meshgrid\n",
    "        spatial_size: spatial size of the tensor to initialize\n",
    "        noise_type: 'u' for uniform; 'n' for normal\n",
    "        var: a factor, a noise will be multiplicated by. Basically it is standard deviation scaler.\n",
    "    \"\"\"\n",
    "    if method == 'noise':\n",
    "        shape = [1, input_depth, noise_size[0], noise_size[1], noise_size[2]]\n",
    "        net_input = torch.zeros(shape)\n",
    "\n",
    "        fill_noise(net_input, noise_type)\n",
    "        net_input *= var\n",
    "    return net_input\n",
    "\n",
    "\n",
    "def central_crop_3D(kspace_arr, factor):\n",
    "    try:\n",
    "        img_tensor = torch.from_numpy(kspace_arr)\n",
    "    except:\n",
    "        img_tensor = kspace_arr\n",
    "\n",
    "    half_boxsize = img_tensor.shape[-1]//(factor*2) #half_boxsize\n",
    "    half_boxsize = int(half_boxsize) # For if factor is not power of 2\n",
    "    # print(img_tensor.shape, img_tensor.shape[-1]/factor/2)\n",
    "\n",
    "    c = img_tensor.shape[-1]//2\n",
    "    start = c-half_boxsize\n",
    "    end = c+half_boxsize\n",
    "    return img_tensor[start:end, start:end, start:end]\n",
    "\n",
    "\n",
    "def torch_sinc_downsampler_3D(arr, factor=2):\n",
    "    try:\n",
    "        img_tensor = torch.from_numpy(arr)\n",
    "    except:\n",
    "        img_tensor = arr\n",
    "\n",
    "    img_tensor_fft = to_k_space(img_tensor)\n",
    "    img_tensor_fft_center = central_crop_3D(img_tensor_fft, factor)\n",
    "    img_back = inv_fft(img_tensor_fft_center)/(factor**3)\n",
    "    return img_back\n",
    "\n",
    "\n",
    "\n",
    "def sinc_upsampler(tensor, hr_size, factor):\n",
    "    tensor = torch.clone(tensor)\n",
    "    lr_ksapce = to_k_space(tensor)\n",
    "    hr_ksapce = lr_ksapce*(factor**3)\n",
    "    \n",
    "    lr_size = tensor.shape[0]\n",
    "    hr_size = 192\n",
    "    p_size = (hr_size - lr_size)//2 # two sides\n",
    "\n",
    "    padded_hr_ksapce = F.pad(hr_ksapce, (p_size,p_size,p_size,p_size,p_size,p_size))\n",
    "    upsampled_tensor = inv_fft(padded_hr_ksapce)\n",
    "    upsampled_tensor = torch.clamp(upsampled_tensor, 0, 1)\n",
    "    return upsampled_tensor\n",
    "\n",
    "\n",
    "def central_replacement_3d(hr_img, dip_img, factor=2):\n",
    "    hr_img_kspace = to_k_space(hr_img)\n",
    "    dip_img_kspace = to_k_space(dip_img)\n",
    "    hr_img_kspace_center = central_crop_3D(hr_img_kspace, factor)\n",
    "\n",
    "    hr_size = dip_img_kspace.shape[-1]\n",
    "    #box_size = hr_size//factor\n",
    "    #box_size = box_size//2*2 # when box_size is odd, it will create one pixel shift, so we need to eliminate it\n",
    "    #start = (hr_size - box_size)//2\n",
    "    #end = (hr_size + box_size)//2\n",
    "    #Start is 128.0 -> 128 for later indexing use\n",
    "    #start, end = int(start), int(end)\n",
    "    \n",
    "    half_boxsize = hr_size//(factor*2) #half_boxsize\n",
    "    half_boxsize = int(half_boxsize) # For if factor is not power of 2\n",
    "    c = hr_size//2\n",
    "    start = c-half_boxsize\n",
    "    end = c+half_boxsize\n",
    "\n",
    "    dip_img_kspace_replaced = torch.clone(dip_img_kspace)   \n",
    "    dip_img_kspace_replaced[start:end, start:end, start:end] = hr_img_kspace_center\n",
    "\n",
    "    dip_img_central_replacement = inv_fft(dip_img_kspace_replaced).numpy()\n",
    "    return dip_img_central_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wGv6dHW9FsYg",
   "metadata": {
    "id": "wGv6dHW9FsYg"
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "def volumetric_psnr(img_in, img_out):\n",
    "    try:\n",
    "        img_out = img_out.cpu().detach().numpy()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    img_in = img_in[5:-5,5:-5,5:-5]\n",
    "    img_out = img_out[5:-5,5:-5,5:-5]\n",
    "    pixel_num = img_in.shape[-1]\n",
    "\n",
    "    _mse_ = ((img_out-img_in)**2).sum()/(pixel_num**3)\n",
    "    _psnr = 20*np.log10(1) - 10*np.log10(_mse_)\n",
    "\n",
    "    return _psnr\n",
    "\n",
    "def psnr_3D(img_in, img_out):\n",
    "    img_out = img_out.cpu().detach().numpy()\n",
    "    if len(img_out.shape) !=3:\n",
    "        raise ValueError(\"Dimension is wrong. img_out.shape=\", img_out.shape)\n",
    "\n",
    "    psnr_arr = []\n",
    "    for i in range(img_in.shape[-1]):\n",
    "        psnr_arr.append(compare_psnr(img_in[:,i,:], img_out[:,i,:]))\n",
    "    return np.array(psnr_arr)\n",
    "\n",
    "\n",
    "def ssim_loss(y_true, y_pred, max_val=1.0):\n",
    "    # Convert 3D objects to tensor\n",
    "    y_true = torch.tensor(y_true, dtype=torch.float32)\n",
    "    y_pred = torch.tensor(y_pred, dtype=torch.float32)\n",
    "\n",
    "    # Calculate mean and variance for y_true and y_pred\n",
    "    mu1 = torch.mean(y_true, dim=[1, 2, 3])\n",
    "    mu2 = torch.mean(y_pred, dim=[1, 2, 3])\n",
    "    sigma1 = torch.var(y_true, dim=[1, 2, 3])\n",
    "    sigma2 = torch.var(y_pred, dim=[1, 2, 3])\n",
    "    sigma12 = torch.mean((y_true - mu1) * (y_pred - mu2), dim=[1, 2, 3])\n",
    "\n",
    "    # Define constants for SSIM calculation\n",
    "    c1 = (0.01 * max_val) ** 2\n",
    "    c2 = (0.03 * max_val) ** 2\n",
    "    ssim = (2 * mu1 * mu2 + c1) * (2 * sigma12 + c2) / ((mu1 ** 2 + mu2 ** 2 + c1) * (sigma1 + sigma2 + c2))\n",
    "    return torch.mean(1 - ssim)\n",
    "\n",
    "\n",
    "def TVLoss3D(image):\n",
    "    # Calculate the total variation of the image\n",
    "    tv = torch.sum(torch.abs(image[:, :, :, :, :-1] - image[:, :, :, :, 1:])) + \\\n",
    "         torch.sum(torch.abs(image[:, :, :, :-1, :] - image[:, :, :, 1:, :])) + \\\n",
    "         torch.sum(torch.abs(image[:, :, :-1, :, :] - image[:, :, 1:, :, :]))\n",
    "    #return tv\n",
    "    return tv/image.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3VvFOBGXcCRX",
   "metadata": {
    "id": "3VvFOBGXcCRX"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "def save_info_dict(item_list, info_path):\n",
    "    output_line = \"\"\n",
    "    \n",
    "    try:\n",
    "        with open(f\"{info_path}.pkl\", 'rb') as pickle_file:\n",
    "            info_dict = pickle.load(pickle_file)\n",
    "    except:\n",
    "        info_dict = defaultdict(list)\n",
    "    \n",
    "    for item_name, value in item_list:\n",
    "        item_info = item_name%value\n",
    "        info_dict[item_info.split(\" \")[0]].append(item_info.split(\" \")[1])\n",
    "        output_line += item_info\n",
    "        output_line += \"  \"\n",
    "        \n",
    "    with open(f\"{info_path}.pkl\", \"wb\") as pickle_file:\n",
    "        pickle.dump(info_dict, pickle_file)\n",
    "    \n",
    "    return output_line\n",
    "\n",
    "def print_and_save(text, output_file):\n",
    "    with open(output_file, \"a\") as file:\n",
    "        print(text)\n",
    "        file.write(text + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuClass": "premium",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
